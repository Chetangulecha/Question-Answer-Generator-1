{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563bf2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pratik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from nltk import tokenize\n",
    "from scipy import stats\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9588bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBold(string):\n",
    "    display(Markdown('**' + string + '**'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a86028",
   "metadata": {},
   "source": [
    "### Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c86873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "\n",
    "def dumpPickle(fileName, content):\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "def loadPickle(fileName):    \n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return content\n",
    "    \n",
    "def pickleExists(fileName):\n",
    "    file = Path(fileName)\n",
    "    \n",
    "    if file.is_file():\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f912d",
   "metadata": {},
   "source": [
    "### Reading datasets\n",
    "Here we could combine datasets to figure out how question and answers are formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6409a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('./data/squad-v1/train-v1.1.json', orient='column')\n",
    "dev = pd.read_json('./data/squad-v1/dev-v1.1.json', orient='column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d143e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, dev], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afab8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'University_of_Notre_Dame', 'paragra...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Montana', 'paragraphs': [{'context'...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'Genocide', 'paragraphs': [{'context...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'Antibiotics', 'paragraphs': [{'cont...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  version\n",
       "0  {'title': 'University_of_Notre_Dame', 'paragra...      1.1\n",
       "1  {'title': 'Beyoncé', 'paragraphs': [{'context'...      1.1\n",
       "2  {'title': 'Montana', 'paragraphs': [{'context'...      1.1\n",
       "3  {'title': 'Genocide', 'paragraphs': [{'context...      1.1\n",
       "4  {'title': 'Antibiotics', 'paragraphs': [{'cont...      1.1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3cdcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showQuestion(titleId, paragraphId, questionId):\n",
    "\n",
    "    title = df['data'][titleId]['title']\n",
    "    paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "    question = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['question']\n",
    "    answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "    answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "\n",
    "    printBold('Title')\n",
    "    print(title)\n",
    "    printBold('Paragraph')\n",
    "    print(paragraph)\n",
    "    printBold('Question')\n",
    "    print(question)\n",
    "    printBold('Answer')\n",
    "    print(answerStart)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd064893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "Saint Bernadette Soubirous\n"
     ]
    }
   ],
   "source": [
    "titleId = 0\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb324f0d",
   "metadata": {},
   "source": [
    "### Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edda4e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles 490\n",
      "Paragraphs 20963\n",
      "Questions 98169\n"
     ]
    }
   ],
   "source": [
    "titlesCount = len(df['data'])\n",
    "totalParagraphsCount = 0\n",
    "totalQuestionsCount = 0\n",
    "\n",
    "for titleId in range(titlesCount):\n",
    "    paragraphsCount = len(df['data'][titleId]['paragraphs'])\n",
    "    totalParagraphsCount += paragraphsCount\n",
    "    \n",
    "    for paragraphId in range(paragraphsCount):\n",
    "        questionsCount = len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])\n",
    "        \n",
    "        totalQuestionsCount += questionsCount\n",
    "        \n",
    "print('Titles', titlesCount)\n",
    "print('Paragraphs', totalParagraphsCount)\n",
    "print('Questions', totalQuestionsCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a69e1b",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82db7fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n",
      "Beyoncé\n",
      "Montana\n",
      "Genocide\n",
      "Antibiotics\n",
      "Frédéric_Chopin\n",
      "Sino-Tibetan_relations_during_the_Ming_dynasty\n",
      "IPod\n",
      "The_Legend_of_Zelda:_Twilight_Princess\n",
      "Spectre_(2015_film)\n",
      "2008_Sichuan_earthquake\n",
      "New_York_City\n",
      "To_Kill_a_Mockingbird\n",
      "Solar_energy\n",
      "Tajikistan\n",
      "Anthropology\n",
      "Portugal\n",
      "Kanye_West\n",
      "Buddhism\n",
      "American_Idol\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "for titleId in range(len(df['data'])):\n",
    "    titles.append(df['data'][titleId]['title'])\n",
    "    \n",
    "for i in range(20):\n",
    "    print(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92236f",
   "metadata": {},
   "source": [
    "### Questions\n",
    "We thought of removing an answer from sentence and convert that sentence to a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be4df821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "Saint Bernadette Soubirous\n"
     ]
    }
   ],
   "source": [
    "titleId = 0\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ddd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSentence(paragraph, answerStart):\n",
    "    \n",
    "    sentences = tokenize.sent_tokenize(paragraph)\n",
    "    sentenceStart = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if (sentenceStart + len(sentence) >= answerStart):\n",
    "            return sentence         \n",
    "        \n",
    "        sentenceStart += len(sentence) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142f6ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n"
     ]
    }
   ],
   "source": [
    "paragraph = df['data'][0]['paragraphs'][0]['context']\n",
    "answerStart = df['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start']\n",
    "\n",
    "sentence = extractSentence(paragraph, answerStart)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e260ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containedInText(text, question):\n",
    "    \n",
    "    questionWords = tokenize.word_tokenize(question.lower())\n",
    "    textWords = tokenize.word_tokenize(text.lower())\n",
    "    wordsContained = 0\n",
    "\n",
    "    for questionWord in questionWords:\n",
    "        for textWord in textWords:\n",
    "            if (questionWord == textWord):\n",
    "                wordsContained += 1\n",
    "                break\n",
    "\n",
    "    return wordsContained / len(questionWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87340438",
   "metadata": {},
   "outputs": [],
   "source": [
    "question =  df['data'][0]['paragraphs'][0]['qas'][0]['question']\n",
    "\n",
    "contained = containedInText(sentence, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a32916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Sentence**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Contained**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6428571428571429\n"
     ]
    }
   ],
   "source": [
    "printBold('Question')\n",
    "print(question)\n",
    "printBold('Sentence')\n",
    "print(sentence)\n",
    "printBold(\"Contained\")\n",
    "print(contained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded0fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print percent of work done\n",
    "def printPercentage(currentStep, maxStep):\n",
    "    stepSize = maxStep / 100\n",
    "    \n",
    "    if (int(currentStep / stepSize) > ((currentStep - 1) / stepSize)):\n",
    "        clear_output()\n",
    "        print('{}%'.format(int(currentStep / stepSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67bb47fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "Result not pickled. Generating...\n"
     ]
    }
   ],
   "source": [
    "questionContainmentDfPickleName = 'data/pickles/questionContainmentDf.pkl'\n",
    "\n",
    "#If the dataframe is already generated, load it.\n",
    "if (pickleExists(questionContainmentDfPickleName)):\n",
    "    print(\"Pickle found. Saved some time.\")\n",
    "    questionContainmentDf = loadPickle(questionContainmentDfPickleName)\n",
    "else:\n",
    "    sentenceScore = []\n",
    "    paragraphScore = []\n",
    "\n",
    "    #For each title\n",
    "    titlesCount = len(df['data'])\n",
    "    for titleId in range(titlesCount):\n",
    "        printPercentage(titleId, titlesCount)\n",
    "\n",
    "        #For each paragraph\n",
    "        for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "            paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "\n",
    "            #For each question\n",
    "            for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "                question = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['question']\n",
    "                answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "                sentence = extractSentence(paragraph, answerStart)\n",
    "\n",
    "                sentenceScore.append(containedInText(sentence, question))\n",
    "                paragraphScore.append(containedInText(paragraph, question))           \n",
    "                \n",
    "    #Merge dataframes into one                \n",
    "    sentenceScoreDf = pd.DataFrame(sentenceScore, columns=['sentence'])\n",
    "    paragraphScoreDf = pd.DataFrame(paragraphScore, columns=['paragraph'])\n",
    "\n",
    "    questionContainmentDf = pd.concat([sentenceScoreDf, paragraphScoreDf], axis=1)\n",
    "    \n",
    "    #Pickle the result\n",
    "    dumpPickle(questionContainmentDfPickleName, questionContainmentDf)\n",
    "    \n",
    "    print(\"Result not pickled. Generating...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6154b425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence  paragraph\n",
       "0  0.642857   0.571429\n",
       "1  0.636364   0.636364\n",
       "2  0.533333   0.600000\n",
       "3  0.375000   0.500000\n",
       "4  0.333333   0.416667\n",
       "5  0.272727   0.636364\n",
       "6  0.300000   0.800000\n",
       "7  0.363636   0.727273\n",
       "8  0.000000   0.545455\n",
       "9  0.266667   0.733333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bee7b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>98169.000000</td>\n",
       "      <td>98169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.463967</td>\n",
       "      <td>0.582192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.190377</td>\n",
       "      <td>0.159048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence     paragraph\n",
       "count  98169.000000  98169.000000\n",
       "mean       0.463967      0.582192\n",
       "std        0.190377      0.159048\n",
       "min        0.000000      0.000000\n",
       "25%        0.333333      0.500000\n",
       "50%        0.461538      0.600000\n",
       "75%        0.600000      0.700000\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "633b18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuestionAt(index):\n",
    "    currentIndex = 0\n",
    "    \n",
    "    for titleId in range(len(df['data'])):\n",
    "        for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "            for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "                if (currentIndex == index):\n",
    "                    return titleId, paragraphId, questionId\n",
    "                currentIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6c0ab43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510b97d",
   "metadata": {},
   "source": [
    "### 0% in senetence/paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a31066a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University_of_Notre_Dame\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many student news papers are found at Notre Dame?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "three\n"
     ]
    }
   ],
   "source": [
    "# 0%\n",
    "titleId = 0\n",
    "paragraphId = 1 \n",
    "questionId = 3\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "358e2826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence  paragraph\n",
       "269        0.0        0.0\n",
       "363        0.0        0.0\n",
       "505        0.0        0.0\n",
       "2781       0.0        0.0\n",
       "3678       0.0        0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf[questionContainmentDf['paragraph'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a71f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(269)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2990be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When did Beyonce start becoming popular?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "in the late 1990s\n"
     ]
    }
   ],
   "source": [
    "titleId = 1\n",
    "paragraphId = 0 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b6a5a",
   "metadata": {},
   "source": [
    "Synonyms are used in this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e41a1d",
   "metadata": {},
   "source": [
    "### 100% in sentence/paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9b5de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45064</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53226</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67425</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  paragraph\n",
       "21911       1.0        1.0\n",
       "39394       1.0        1.0\n",
       "45064       1.0        1.0\n",
       "48874       1.0        1.0\n",
       "53226       1.0        1.0\n",
       "67425       1.0        1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionContainmentDf[questionContainmentDf['sentence'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11bf1515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 23, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getQuestionAt(53226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "738c36d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Title**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrecht\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Paragraph**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utrecht city has an active cultural life, and in the Netherlands is second only to Amsterdam. There are several theatres and theatre companies. The 1941 main city theatre was built by Dudok. Besides theatres there is a large number of cinemas including three arthouse cinemas. Utrecht is host to the international Early Music Festival (Festival Oude Muziek, for music before 1800) and the Netherlands Film Festival. The city has an important classical music hall Vredenburg (1979 by Herman Hertzberger). Its acoustics are considered among the best of the 20th-century original music halls.[citation needed] The original Vredenburg music hall has been redeveloped as part of the larger station area redevelopment plan and in 2014 has gained additional halls that allowed its merger with the rock club Tivoli and the SJU jazzpodium. There are several other venues for music throughout the city. Young musicians are educated in the conservatory, a department of the Utrecht School of the Arts. There is a specialised museum of automatically playing musical instruments.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultural life in Utrecht is second to \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answer**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Utrecht city has an active cultural life, and in the Netherlands is second only to Amsterdam\n"
     ]
    }
   ],
   "source": [
    "titleId = 258\n",
    "paragraphId = 23 \n",
    "questionId = 0\n",
    "\n",
    "showQuestion(titleId, paragraphId, questionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da0257",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2147fcb",
   "metadata": {},
   "source": [
    "**Question is mostly consisted of words from the sentence the answer is present**\n",
    "\n",
    "There are some obvious differences like:\n",
    "- Question-like words are added - who, why...\n",
    "- Synonyms are used.\n",
    "- tense of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d154bd",
   "metadata": {},
   "source": [
    "### Answers in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "507df941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Answers in text**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98169\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Answers not in text**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "answersInText = 0\n",
    "answersNotInText = 0\n",
    "\n",
    "for titleId in range(len(df['data'])):\n",
    "     for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "        paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "        for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "            answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "            if (answer in paragraph):\n",
    "                answersInText += 1\n",
    "            else:\n",
    "                answersNotInText += 1\n",
    "                \n",
    "printBold('Answers in text')\n",
    "print(answersInText)\n",
    "printBold('Answers not in text')\n",
    "print(answersNotInText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "124618ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "sentences = []\n",
    "\n",
    "for titleId in range(len(df['data'])):\n",
    "    \n",
    "     for paragraphId in range(len(df['data'][titleId]['paragraphs'])):\n",
    "        paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "        \n",
    "        for questionId in range(len(df['data'][titleId]['paragraphs'][paragraphId]['qas'])):\n",
    "            answer = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['text']\n",
    "            answerStart = df['data'][titleId]['paragraphs'][paragraphId]['qas'][questionId]['answers'][0]['answer_start']\n",
    "            \n",
    "            sentence = extractSentence(paragraph, answerStart)\n",
    "            \n",
    "            answers.append(answer)\n",
    "            sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73cbf5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the Main Building</td>\n",
       "      <td>Next to the Main Building is the Basilica of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    answer  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                            sentence  \n",
       "0  It is a replica of the grotto at Lourdes, Fran...  \n",
       "1  Immediately in front of the Main Building and ...  \n",
       "2  Next to the Main Building is the Basilica of t...  \n",
       "3  Immediately behind the basilica is the Grotto,...  \n",
       "4  Atop the Main Building's gold dome is a golden...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerTextsDf = pd.DataFrame(answers, columns=['answer'])\n",
    "sentenceDf = pd.DataFrame(sentences, columns=['sentence'])\n",
    "\n",
    "answersDf = pd.concat([answerTextsDf, sentenceDf], axis=1)\n",
    "answersDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6cb29e",
   "metadata": {},
   "source": [
    "### Answer word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a64bf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = []\n",
    "\n",
    "for i in range(len(answersDf)):\n",
    "    wordCount.append(len(tokenize.word_tokenize(answersDf.iloc[i]['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a9a7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDf = pd.concat([answersDf, pd.DataFrame(wordCount, columns=['wordCount'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29c806f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    98169.000000\n",
       "mean         3.355031\n",
       "std          3.731700\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          4.000000\n",
       "max         46.000000\n",
       "Name: wordCount, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf['wordCount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74f457b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     32156\n",
       "2     25228\n",
       "3     14348\n",
       "4      7562\n",
       "5      4659\n",
       "6      3051\n",
       "7      2222\n",
       "8      1676\n",
       "9      1206\n",
       "10      975\n",
       "11      755\n",
       "12      652\n",
       "13      566\n",
       "14      461\n",
       "15      407\n",
       "16      313\n",
       "18      274\n",
       "17      269\n",
       "19      244\n",
       "20      191\n",
       "21      182\n",
       "23      138\n",
       "22      131\n",
       "25      120\n",
       "24      101\n",
       "26       77\n",
       "28       59\n",
       "27       58\n",
       "29       28\n",
       "30       19\n",
       "31       12\n",
       "32       11\n",
       "33        6\n",
       "38        2\n",
       "34        2\n",
       "35        2\n",
       "36        2\n",
       "37        2\n",
       "42        1\n",
       "46        1\n",
       "Name: wordCount, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf['wordCount'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c679f8",
   "metadata": {},
   "source": [
    "we could see 1/3 answers are one word only and two words answers could be the names of places, people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6ef6aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "      <th>wordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62843</th>\n",
       "      <td>25 genes</td>\n",
       "      <td>By the end of 2005, 25 genes had been associat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>In 2006, Lee was awarded an honorary doctorate...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44145</th>\n",
       "      <td>Charles Pillsbury</td>\n",
       "      <td>There he met fellow student and later Green Pa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68124</th>\n",
       "      <td>Lionel Robbins</td>\n",
       "      <td>With the help of Mises, in the late 1920s Haye...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>The Beatles</td>\n",
       "      <td>The single, \"A Moment Like This\", went on to b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37185</th>\n",
       "      <td>Prince Albert</td>\n",
       "      <td>Victoria married her first cousin, Prince Albe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72091</th>\n",
       "      <td>Western Railroad</td>\n",
       "      <td>It was formerly used by the Milwaukee Road fro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>Mockingbird groupies</td>\n",
       "      <td>Local residents call them \"Mockingbird groupie...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89845</th>\n",
       "      <td>two points</td>\n",
       "      <td>Luther's rediscovery of \"Christ and His salvat...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17988</th>\n",
       "      <td>Copeland Award</td>\n",
       "      <td>Kansas also won the 1981–82 Copeland Award.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92556</th>\n",
       "      <td>100–106 °F</td>\n",
       "      <td>The modern bubonic plague has a mortality rate...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>Indo-European languages</td>\n",
       "      <td>The Uralic languages do not belong to the Indo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>common sense</td>\n",
       "      <td>They begin to differentiate between rules inst...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90452</th>\n",
       "      <td>Dolby Digital</td>\n",
       "      <td>BSkyB's standard definition broadcasts are in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48587</th>\n",
       "      <td>1 billion</td>\n",
       "      <td>The Carnival industry chain amassed in 2012 al...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>learning investments</td>\n",
       "      <td>Hence the additional costs of the incentives f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59158</th>\n",
       "      <td>built-in microphone</td>\n",
       "      <td>A single device may provide several functions,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>Jennifer Hudson</td>\n",
       "      <td>Other alumni have gone on to work in televisio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>elementary ideas</td>\n",
       "      <td>According to Bastian, all human societies shar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82507</th>\n",
       "      <td>Han Chinese</td>\n",
       "      <td>Han Chinese Banners were made up of Han Chines...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        answer  \\\n",
       "62843                 25 genes   \n",
       "4799                Notre Dame   \n",
       "44145        Charles Pillsbury   \n",
       "68124           Lionel Robbins   \n",
       "7152               The Beatles   \n",
       "37185            Prince Albert   \n",
       "72091         Western Railroad   \n",
       "4851      Mockingbird groupies   \n",
       "89845               two points   \n",
       "17988           Copeland Award   \n",
       "92556               100–106 °F   \n",
       "15881  Indo-European languages   \n",
       "30814             common sense   \n",
       "90452            Dolby Digital   \n",
       "48587                1 billion   \n",
       "5075      learning investments   \n",
       "59158      built-in microphone   \n",
       "7646           Jennifer Hudson   \n",
       "59943         elementary ideas   \n",
       "82507              Han Chinese   \n",
       "\n",
       "                                                sentence  wordCount  \n",
       "62843  By the end of 2005, 25 genes had been associat...          2  \n",
       "4799   In 2006, Lee was awarded an honorary doctorate...          2  \n",
       "44145  There he met fellow student and later Green Pa...          2  \n",
       "68124  With the help of Mises, in the late 1920s Haye...          2  \n",
       "7152   The single, \"A Moment Like This\", went on to b...          2  \n",
       "37185  Victoria married her first cousin, Prince Albe...          2  \n",
       "72091  It was formerly used by the Milwaukee Road fro...          2  \n",
       "4851   Local residents call them \"Mockingbird groupie...          2  \n",
       "89845  Luther's rediscovery of \"Christ and His salvat...          2  \n",
       "17988        Kansas also won the 1981–82 Copeland Award.          2  \n",
       "92556  The modern bubonic plague has a mortality rate...          2  \n",
       "15881  The Uralic languages do not belong to the Indo...          2  \n",
       "30814  They begin to differentiate between rules inst...          2  \n",
       "90452  BSkyB's standard definition broadcasts are in ...          2  \n",
       "48587  The Carnival industry chain amassed in 2012 al...          2  \n",
       "5075   Hence the additional costs of the incentives f...          2  \n",
       "59158  A single device may provide several functions,...          2  \n",
       "7646   Other alumni have gone on to work in televisio...          2  \n",
       "59943  According to Bastian, all human societies shar...          2  \n",
       "82507  Han Chinese Banners were made up of Han Chines...          2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf[answersDf['wordCount'] == 2].sample(n=20, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d65ebd",
   "metadata": {},
   "source": [
    "### Word types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3fa20",
   "metadata": {},
   "source": [
    "**Spacy** turned out be a pretty great tool which could provide me with *NER (Named entity recognition), part of speech detection, word embeddings similarity* and some more functions which may or may be useful in my case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0d53094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "132480ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('European', 'NORP'), ('Google', 'ORG'), ('$5.1 billion', 'MONEY'), ('Wednesday', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "664de575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NerForWord(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    entitiesFound = len(doc.ents)\n",
    "    \n",
    "    if (entitiesFound > 0):\n",
    "        #TODO - Could potentially find multiple entities in the text. We're returning only the first one.\n",
    "        return doc.ents[0].label_\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62a2ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSingleToken(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    #The entire text is a single named entity \n",
    "    entitiesFound = len(doc.ents)\n",
    "    if(entitiesFound == 1 and doc.ents[0].text == text):\n",
    "        return True\n",
    "    \n",
    "    #The text is not an named entity, but is a single token\n",
    "    tokensFound = len(doc)\n",
    "    if (tokensFound == 1):\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b94ffc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDf['isSingleToken'] = False\n",
    "answersDf['NER'] = ''\n",
    "answersDf['POS'] = ''\n",
    "answersDf['TAG'] = ''\n",
    "answersDf['DEP'] = ''\n",
    "answersDf['shape'] = ''\n",
    "answersDf['isAlpha'] = False\n",
    "answersDf['isStop'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4876468e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>isSingleToken</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>isAlpha</th>\n",
       "      <th>isStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the Main Building</td>\n",
       "      <td>Next to the Main Building is the Basilica of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    answer  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                            sentence  wordCount  \\\n",
       "0  It is a replica of the grotto at Lourdes, Fran...          3   \n",
       "1  Immediately in front of the Main Building and ...          5   \n",
       "2  Next to the Main Building is the Basilica of t...          3   \n",
       "3  Immediately behind the basilica is the Grotto,...          7   \n",
       "4  Atop the Main Building's gold dome is a golden...          7   \n",
       "\n",
       "   isSingleToken NER POS TAG DEP shape  isAlpha  isStop  \n",
       "0          False                          False   False  \n",
       "1          False                          False   False  \n",
       "2          False                          False   False  \n",
       "3          False                          False   False  \n",
       "4          False                          False   False  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ff7aa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n"
     ]
    }
   ],
   "source": [
    "singleTokenCount = 0\n",
    "\n",
    "sampleSize = int(len(answersDf) / 10)\n",
    "\n",
    "for i in range(sampleSize):\n",
    "        \n",
    "    printPercentage(i, sampleSize)\n",
    "    \n",
    "    answer = answersDf.iloc[i]['answer']\n",
    "    if (isSingleToken(answer)):\n",
    "        answersDf.at[i, 'isSingleToken'] = True\n",
    "        \n",
    "        answersDf.at[i, 'NER'] = NerForWord(answer)\n",
    "        \n",
    "        #At this point I've called spacy's nlp method 3 times for the same words...\n",
    "        doc = nlp(answer)\n",
    "        \n",
    "        answersDf.at[i, 'POS'] = doc[0].pos_\n",
    "        answersDf.at[i, 'TAG'] = doc[0].tag_\n",
    "        answersDf.at[i, 'DEP'] = doc[0].dep_\n",
    "        answersDf.at[i, 'isAlpha'] = doc[0].is_alpha\n",
    "        answersDf.at[i, 'isStop'] = doc[0].is_stop\n",
    "        \n",
    "        shape = doc[0].shape_\n",
    "        for wordIndex in range(1, len(doc)):\n",
    "            shape += (' ' + doc[wordIndex].shape_)\n",
    "            \n",
    "        answersDf.at[i, 'shape'] = shape\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8053285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>isSingleToken</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>isAlpha</th>\n",
       "      <th>isStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the Main Building</td>\n",
       "      <td>Next to the Main Building is the Basilica of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>ORG</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx Xxxx Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    answer  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                            sentence  wordCount  \\\n",
       "0  It is a replica of the grotto at Lourdes, Fran...          3   \n",
       "1  Immediately in front of the Main Building and ...          5   \n",
       "2  Next to the Main Building is the Basilica of t...          3   \n",
       "3  Immediately behind the basilica is the Grotto,...          7   \n",
       "4  Atop the Main Building's gold dome is a golden...          7   \n",
       "\n",
       "   isSingleToken  NER  POS TAG  DEP           shape  isAlpha  isStop  \n",
       "0          False                                       False   False  \n",
       "1          False                                       False   False  \n",
       "2           True  ORG  DET  DT  det  xxx Xxxx Xxxxx     True    True  \n",
       "3          False                                       False   False  \n",
       "4          False                                       False   False  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bb11c9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    97688\n",
       "True       481\n",
       "Name: isStop, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf['isStop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bfbcc8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               93991\n",
       "CARDINAL         952\n",
       "PERSON           948\n",
       "DATE             927\n",
       "ORG              527\n",
       "GPE              315\n",
       "PERCENT          152\n",
       "MONEY             91\n",
       "NORP              91\n",
       "LOC               39\n",
       "FAC               35\n",
       "QUANTITY          30\n",
       "ORDINAL           29\n",
       "WORK_OF_ART       12\n",
       "TIME               9\n",
       "PRODUCT            8\n",
       "LANGUAGE           7\n",
       "EVENT              6\n",
       "Name: NER, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf['NER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cd8fa728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f791c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>sentence</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>isSingleToken</th>\n",
       "      <th>NER</th>\n",
       "      <th>POS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>shape</th>\n",
       "      <th>isAlpha</th>\n",
       "      <th>isStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1918</td>\n",
       "      <td>In June 1917, the U.S. Congress passed the Esp...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>22 February 1810</td>\n",
       "      <td>The parish baptismal record gives his birthday...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>dd Xxxxx dddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>6.3 percent</td>\n",
       "      <td>According to the 2010 Census, 89.4 percent of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PERCENT</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>nummod</td>\n",
       "      <td>d.d xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>29</td>\n",
       "      <td>Fryderyk Chopin was born in Żelazowa Wola, 46 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>2006</td>\n",
       "      <td>In 2006 Apple presented a special edition for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7573</th>\n",
       "      <td>9.9 million</td>\n",
       "      <td>The first show drew 9.9 million viewers, givin...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>compound</td>\n",
       "      <td>d.d xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>2012</td>\n",
       "      <td>In 2012, New York City topped the first Global...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>18,498</td>\n",
       "      <td>According to Chinese state officials, the quak...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dd,ddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>65</td>\n",
       "      <td>The last opus number that Chopin himself used ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>dd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7580</th>\n",
       "      <td>21.7 million</td>\n",
       "      <td>The season attracted an average of 21.7 millio...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>compound</td>\n",
       "      <td>dd.d xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                answer                                           sentence  \\\n",
       "1168              1918  In June 1917, the U.S. Congress passed the Esp...   \n",
       "1548  22 February 1810  The parish baptismal record gives his birthday...   \n",
       "1134       6.3 percent  According to the 2010 Census, 89.4 percent of ...   \n",
       "1551                29  Fryderyk Chopin was born in Żelazowa Wola, 46 ...   \n",
       "2519              2006  In 2006 Apple presented a special edition for ...   \n",
       "7573       9.9 million  The first show drew 9.9 million viewers, givin...   \n",
       "4221              2012  In 2012, New York City topped the first Global...   \n",
       "3443            18,498  According to Chinese state officials, the quak...   \n",
       "2069                65  The last opus number that Chopin himself used ...   \n",
       "7580      21.7 million  The season attracted an average of 21.7 millio...   \n",
       "\n",
       "      wordCount  isSingleToken       NER  POS TAG       DEP          shape  \\\n",
       "1168          1           True      DATE  NUM  CD      ROOT           dddd   \n",
       "1548          3           True      DATE  NUM  CD    nummod  dd Xxxxx dddd   \n",
       "1134          2           True   PERCENT  NUM  CD    nummod       d.d xxxx   \n",
       "1551          1           True  CARDINAL  NUM  CD      ROOT             dd   \n",
       "2519          1           True      DATE  NUM  CD      ROOT           dddd   \n",
       "7573          2           True  CARDINAL  NUM  CD  compound       d.d xxxx   \n",
       "4221          1           True            NUM  CD      ROOT           dddd   \n",
       "3443          1           True  CARDINAL  NUM  CD      ROOT         dd,ddd   \n",
       "2069          1           True  CARDINAL  NUM  CD      ROOT             dd   \n",
       "7580          2           True  CARDINAL  NUM  CD  compound      dd.d xxxx   \n",
       "\n",
       "      isAlpha  isStop  \n",
       "1168    False   False  \n",
       "1548    False   False  \n",
       "1134    False   False  \n",
       "1551    False   False  \n",
       "2519    False   False  \n",
       "7573    False   False  \n",
       "4221    False   False  \n",
       "3443    False   False  \n",
       "2069    False   False  \n",
       "7580    False   False  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answersDf[answersDf['POS'] == 'NUM'].sample(n=10, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02811df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightAnswers(titleId, paragraphId):\n",
    "\n",
    "    paragraph = df['data'][titleId]['paragraphs'][paragraphId]['context']\n",
    "    \n",
    "    answers = df['data'][titleId]['paragraphs'][paragraphId]['qas']\n",
    "\n",
    "    #Get answer starts and answer length\n",
    "    answerPosition = {}\n",
    "    for answer in answers:\n",
    "        answerStart = answer['answers'][0]['answer_start']\n",
    "        answerLength = len(answer['answers'][0]['text'])\n",
    "\n",
    "        answerPosition[answerStart] = answerLength\n",
    "\n",
    "    #Bold answers\n",
    "    shiftStart = 0\n",
    "    highlightedText = ''\n",
    "    currentPlaceInText = 0\n",
    "    \n",
    "    #Append text between previous answer and current answer + bold sign + answer + bold sign\n",
    "    for answerStart in sorted(answerPosition.keys()):\n",
    "        highlightedText += paragraph[currentPlaceInText:answerStart]\n",
    "        highlightedText += '**'\n",
    "        highlightedText += paragraph[answerStart:answerStart + answerPosition[answerStart]]\n",
    "        highlightedText += '**'\n",
    "        \n",
    "        currentPlaceInText = answerStart + answerPosition[answerStart]\n",
    "    \n",
    "    #Append the remaining text after the last answer\n",
    "    highlightedText += paragraph[currentPlaceInText:len(paragraph)]\n",
    "\n",
    "    #Diplay the highlighted text\n",
    "    display(Markdown(highlightedText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bac80259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Located approximately 250 kilometres (**160** mi) east of Puerto Rico and the nearer Virgin Islands, St. Barthélemy lies immediately southeast of the islands of Saint Martin and Anguilla. It is one of **the Renaissance** Islands. St. Barthélemy is separated from Saint Martin by **the Saint-Barthélemy Channel**. It lies northeast of Saba and St Eustatius, and north of St Kitts. Some small **satellite islets** belong to St. Barthélemy including Île Chevreau (Île Bonhomme), Île Frégate, Île Toc Vers, Île Tortue and Gros Îlets (Îlots Syndare). A much bigger islet, Île Fourchue, lies on the north of the island, in the Saint-Barthélemy Channel. Other rocky islets which include Coco, the Roques (or **little Turtle rocks**), the Goat, and the Sugarloaf."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titleId = 24\n",
    "paragraphId = 0\n",
    "\n",
    "highlightAnswers(titleId, paragraphId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2f97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
